%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\section{The Model Building Process}
Machine learning models have been used in to solve problems in a large number of 
domains. They can be used to recommend movies\cite{patterson:risc}, 
classify tumors as benign or malignant, label objects in images, and more. 
Building these highly predictive machine learning models, however, is not easy. 

A data scientist engaged in the model building process goes through many cycles of
experimentation. For example, in a single cycle, a data scientist may perform the
following steps:

\begin{enumerate}
  \item Apply preprocessing operations to the data.
  \item Split the data into training and test sets.
  \item Select a model type and optimization criterion for training.
  \item Define a hyperparameter search grid for the model.
  \item Use cross validation to evaluate hyperparameter configurations and select a 
    promising mode.
  \item Evaluate the model on the test set
\end{enumerate}

Over many cycles, the data scientist will have created and evaluated many models,
applied various preprocessing pipelines, and tried numerous feature sets and hyperparameter
configurations. Currently, recording the operations performed in these cycles requires
a lot of manual effort. They must write their intermediate data files, models, evaluation metrics,
and preprocessing code to different files. They may invent some ad-hoc directory layout 
and a set of naming conventions to organize this information. Even if the data scientist
diligently records all their cycles, it is not easy for them to glean information from their
recorded data without writing some custom scripts.

Recording information about the model building process help the data scientist 
make better decisions on improving model performance. Comparing hyperparameters
and feature sets may provide insight into why two models differ in performance. 
Examining the most important features may highlight what parts of the dataset are
most useful for prediction. Tracing a model's lineage can show what preprocessing
steps were most effective. Storing evaluation metrics for models can help
the data scientist focus on only the highest quality models. 

Recording information about the model building process can answer some useful 
questions, but currently it is difficult and time-consuming to do.

\section{ModelDB Server and ModelDB Spark Client}

ModelDB Server and ModelDB Spark Client aim to simplify the challenge of recording, storing,
and learning from the model building process. 

ModelDB Spark Client is a lighweight library for Apache Spark's machine learning library (Spark.ML) 
that allows the user to collect information about their machine learning operations with minimal changes to their code. 

The Spark Client sends the information it collects to ModelDB Server, which 
stores the operations and models in a centralized database and the serialized 
models in its filesystem. 

The abstractions used in ModelDB Server are library agnostic. This means ModelDB Server 
and its database schema are not tied to any particular machine learning library, making
it possible to develop clients for other popular machine learning libraries like Python Scikit-learn.

ModelDB Server also exposes an API that allows the user to glean information about their
operations and models. This allows users to compare models, find
similar models, rank models, fetch the steps that produced a model, and more. 

While ModelDB Server has functionality for storing and extracting information from
all kinds of models, it stores extra information and provides richer APIs for 
Logistic Regression, Linear Regression, Decision Tree, Random Forest, and 
Gradient Boosted Tree models. 

Concretly, this thesis makes the following contributions:

\begin{enumerate}
  \item A set of library-agnostic abstractions that can be used to
    represent a wide range of machine learning operations and models.
  \item A number of algorithms that can be applied on the above abstractions
    to gain insight into the model building process.
  \item A working system that can both store data about 
    machine learning operations and models (especially linear and tree models) 
    as well as extract useful information from this data.
  \item A working client library for Spark ML that can collect information 
    about various  machine learning operations and models with 
    minimal required changes to a data scientist's code.
\end{enumerate}


\section{Outline of this Paper}

While ModelDB Server has functionality for storing and extracting information from
all kinds of models, it stores extra information and provides richer APIs for 
Logistic Regression, Linear Regression, Decision Tree, Random Forest, and 
Gradient Boosted Tree models. Therefore, it is worth discussing those models
here.

